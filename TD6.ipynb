{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lire_fichier(didier):\n",
    "    f = open(didier, encoding=\"utf-8\")\n",
    "    chaine = f.read()\n",
    "    f.close()\n",
    "    return chaine\n",
    "\n",
    "import glob\n",
    "documents = {}\n",
    "chemin_corpus = \"corpus_multi/fr/*/*\"\n",
    "\n",
    "for chemin in glob.glob(chemin_corpus):\n",
    "    documents[chemin] = lire_fichier(chemin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_doc = list(documents.keys())\n",
    "#print(documents[liste_doc[23]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "création de l'index\n",
      "Nbr de mots indexés : 33654\n"
     ]
    }
   ],
   "source": [
    "def decouper_mots(chaine):\n",
    "    mots = chaine.split()\n",
    "    return mots\n",
    "def creer_index(documents):\n",
    "    print(\"création de l'index\")\n",
    "    index = {}\n",
    "    for chemin, contenu in documents.items():\n",
    "        mots = decouper_mots(contenu)\n",
    "        vocabulaire = set(mots)\n",
    "        for mot in vocabulaire:\n",
    "            if mot not in index:\n",
    "                index[mot] = []\n",
    "            index[mot].append(chemin)\n",
    "    return index\n",
    "\n",
    "index = creer_index(documents)\n",
    "print(\"Nbr de mots indexés :\", len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "création de l'index inverse\n",
      "Nbr de textes indexés : 272\n"
     ]
    }
   ],
   "source": [
    "def creer_index_inverse(documents):\n",
    "    print(\"création de l'index inverse\")\n",
    "    index_inverse = {}\n",
    "    for chemin, contenu in documents.items():\n",
    "        mots = decouper_mots(contenu)\n",
    "        dic_frequence = {}\n",
    "        for mot in mots:   \n",
    "            if mot not in dic_frequence:\n",
    "                dic_frequence[mot]=0\n",
    "            dic_frequence[mot]+=1\n",
    "            #compter les occurrences dans dic\n",
    "        index_inverse[chemin] = dic_frequence\n",
    "    return index_inverse\n",
    "index_inverse = creer_index_inverse(documents)\n",
    "print(\"Nbr de textes indexés :\", len(index_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'moteur': 2, 'vais': 1, 'tester': 1}\n"
     ]
    }
   ],
   "source": [
    "def indexer_requete(requete):\n",
    "    index_requete = {}\n",
    "    mots = decouper_mots(requete)\n",
    "    for mot in mots:   \n",
    "        if mot not in index_requete:\n",
    "            index_requete[mot]=0\n",
    "        index_requete[mot]+=1\n",
    "    return index_requete\n",
    "requete = \"moteur vais tester moteur\"\n",
    "index_requete = indexer_requete(requete)\n",
    "print(index_requete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moteur\n",
      "['corpus_multi/fr/test/2009-02-20_celex_IP-09-300.fr.html', 'corpus_multi/fr/test/2009-01-28_celex_IP-09-141.fr.html', 'corpus_multi/fr/appr/2009-12-16_celex_IP-09-1950.fr.html', 'corpus_multi/fr/appr/2009-04-20_celex_IP-09-594.fr.html', 'corpus_multi/fr/appr/2009-01-19_celex_IP-09-67.fr.html', 'corpus_multi/fr/appr/2009-02-19_celex_IP-09-297.fr.html', 'corpus_multi/fr/appr/2009-06-19_celex_IP-09-967.fr.html', 'corpus_multi/fr/appr/2009-09-22_celex_IP-09-1341.fr.html', 'corpus_multi/fr/appr/2009-03-04_celex_IP-09-351.fr.html', 'corpus_multi/fr/appr/2009-05-06_celex_IP-09-704.fr.html', 'corpus_multi/fr/appr/2009-08-04_celex_IP-09-1221.fr.html', 'corpus_multi/fr/appr/2009-11-27_celex_IP-09-1837.fr.html', 'corpus_multi/fr/appr/2009-06-18_celex_IP-09-952.fr.html', 'corpus_multi/fr/appr/2009-11-12_celex_IP-09-1703.fr.html', 'corpus_multi/fr/appr/2009-12-18_celex_IP-09-1966.fr.html', 'corpus_multi/fr/appr/2009-01-28_celex_IP-09-131.fr.html', 'corpus_multi/fr/appr/2009-06-18_celex_IP-09-951.fr.html']\n",
      "tester\n",
      "['corpus_multi/fr/test/2009-12-21_celex_IP-09-1988.fr.html', 'corpus_multi/fr/appr/2009-10-15_celex_IP-09-1530.fr.html', 'corpus_multi/fr/appr/2009-11-23_celex_IP-09-1802.fr.html']\n"
     ]
    }
   ],
   "source": [
    "for mot in index_requete:   \n",
    "    if mot in index:\n",
    "        print(mot)\n",
    "        print(index[mot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensibilisation minorités\n",
      "Nbr de documents trouvés : 9\n",
      "liberté humaine\n",
      "Nbr de documents trouvés : 23\n"
     ]
    }
   ],
   "source": [
    "def requeter_documents(requete, index):\n",
    "    index_requete = indexer_requete(requete)\n",
    "    documents_trouves = []\n",
    "    for mot in index_requete:\n",
    "        if mot in index:\n",
    "            documents_pertinents = index[mot]\n",
    "            documents_trouves+=documents_pertinents\n",
    "    return set(documents_trouves)\n",
    "requete = \"sensibilisation minorités\"\n",
    "documents_trouves =  requeter_documents(requete, index)\n",
    "\n",
    "print(requete)\n",
    "print(\"Nbr de documents trouvés :\", len(documents_trouves))\n",
    "requete = \"liberté humaine\"\n",
    "documents_trouves =  requeter_documents(requete, index)\n",
    "print(requete)\n",
    "print(\"Nbr de documents trouvés :\", len(documents_trouves))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculer_similarite_cosinus(requete, index_inverse,documents_trouves):\n",
    "    from scipy import spatial\n",
    "    \n",
    "    index_requete = indexer_requete(requete)#pour avoir la même structure de dico mot:effectif\n",
    "    resultat = []# où on va stocker les docs et les similarités\n",
    "    \n",
    "    for doc in documents_trouves:\n",
    "        #On fait l'union des mots du document en cours et de la requête :\n",
    "        vocabulaire = set(index_requete.keys()).union(index_inverse[doc].keys())\n",
    "        \n",
    "        #On aura un vecteur pour chacun\n",
    "        vecteur, vecteur_requete = [], []\n",
    "        \n",
    "        for mot in vocabulaire:\n",
    "            if mot in index_inverse[doc]:#si le mot est dans le document\n",
    "                vecteur.append(index_inverse[doc][mot])#on ajoute son effectif dans le vecteur\n",
    "            else:\n",
    "                vecteur.append(0)# Sile mot est absent de ce document, on ajoute un zéro\n",
    "                \n",
    "            if mot in index_requete:#Idem pour la requête\n",
    "                vecteur_requete.append(index_requete[mot])\n",
    "            else:\n",
    "                vecteur_requete.append(0)#= le mot est absent de la requête\n",
    "        dist=spatial.distance.cosine(vecteur,vecteur_requete )\n",
    "        similarite = 1-dist\n",
    "        resultat.append([similarite, doc])\n",
    "\n",
    "    return resultat # en sortie, des paires [similarité, document]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m index_requete \u001b[39m=\u001b[39m indexer_requete(requete)\n\u001b[1;32m      3\u001b[0m documents_trouves \u001b[39m=\u001b[39m  requeter_documents(requete, index)\n\u001b[0;32m----> 4\u001b[0m resultat \u001b[39m=\u001b[39m calculer_similarite_cosinus(requete, index_inverse, documents_trouves)\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(resultat, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(res)\n",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m, in \u001b[0;36mcalculer_similarite_cosinus\u001b[0;34m(requete, index_inverse, documents_trouves)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculer_similarite_cosinus\u001b[39m(requete, index_inverse,documents_trouves):\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m spatial\n\u001b[1;32m      4\u001b[0m     index_requete \u001b[39m=\u001b[39m indexer_requete(requete)\u001b[39m#pour avoir la même structure de dico mot:effectif\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     resultat \u001b[39m=\u001b[39m []\u001b[39m# où on va stocker les docs et les similarités\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "requete = \"moteur vais tester moteur\"\n",
    "index_requete = indexer_requete(requete)\n",
    "documents_trouves =  requeter_documents(requete, index)\n",
    "resultat = calculer_similarite_cosinus(requete, index_inverse, documents_trouves)\n",
    "for res in sorted(resultat, reverse=True):\n",
    "    print(res)\n",
    "\n",
    "requete = \"la solidarité\"\n",
    "index_requete = indexer_requete(requete)\n",
    "documents_trouves =  requeter_documents(requete, index)\n",
    "resultat = calculer_similarite_cosinus(requete, index_inverse, documents_trouves)\n",
    "for res in sorted(resultat, reverse=True):\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m resultat\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m requete \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mla solidarité\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtoto titi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdroit travail\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m---> 12\u001b[0m     resultat \u001b[39m=\u001b[39m traiter_requete(requete, index, index_inverse)\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPour la requête \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m résultats)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m(requete, \u001b[39mlen\u001b[39m(resultat)))\n\u001b[1;32m     14\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(resultat, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[:\u001b[39m10\u001b[39m]:\u001b[39m#On se limite aux dix premiers résultats\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [10], line 7\u001b[0m, in \u001b[0;36mtraiter_requete\u001b[0;34m(requete, index, index_inverse)\u001b[0m\n\u001b[1;32m      5\u001b[0m index_requete \u001b[39m=\u001b[39m indexer_requete(requete)\n\u001b[1;32m      6\u001b[0m documents_trouves \u001b[39m=\u001b[39m  requeter_documents(requete, index)\n\u001b[0;32m----> 7\u001b[0m resultat \u001b[39m=\u001b[39m calculer_similarite_cosinus(requete, index_inverse, documents_trouves)\n\u001b[1;32m      8\u001b[0m \u001b[39mreturn\u001b[39;00m resultat\n",
      "Cell \u001b[0;32mIn [9], line 6\u001b[0m, in \u001b[0;36mcalculer_similarite_cosinus\u001b[0;34m(requete, index_inverse, documents_trouves)\u001b[0m\n\u001b[1;32m      4\u001b[0m index_requete \u001b[39m=\u001b[39m indexer_requete(requete)\n\u001b[1;32m      5\u001b[0m documents_trouves \u001b[39m=\u001b[39m  requeter_documents(requete, index)\n\u001b[0;32m----> 6\u001b[0m resultat \u001b[39m=\u001b[39m calculer_similarite_cosinus(requete, index_inverse, documents_trouves)\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(resultat, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(res)\n",
      "Cell \u001b[0;32mIn [9], line 6\u001b[0m, in \u001b[0;36mcalculer_similarite_cosinus\u001b[0;34m(requete, index_inverse, documents_trouves)\u001b[0m\n\u001b[1;32m      4\u001b[0m index_requete \u001b[39m=\u001b[39m indexer_requete(requete)\n\u001b[1;32m      5\u001b[0m documents_trouves \u001b[39m=\u001b[39m  requeter_documents(requete, index)\n\u001b[0;32m----> 6\u001b[0m resultat \u001b[39m=\u001b[39m calculer_similarite_cosinus(requete, index_inverse, documents_trouves)\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(resultat, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(res)\n",
      "    \u001b[0;31m[... skipping similar frames: calculer_similarite_cosinus at line 6 (2965 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn [9], line 6\u001b[0m, in \u001b[0;36mcalculer_similarite_cosinus\u001b[0;34m(requete, index_inverse, documents_trouves)\u001b[0m\n\u001b[1;32m      4\u001b[0m index_requete \u001b[39m=\u001b[39m indexer_requete(requete)\n\u001b[1;32m      5\u001b[0m documents_trouves \u001b[39m=\u001b[39m  requeter_documents(requete, index)\n\u001b[0;32m----> 6\u001b[0m resultat \u001b[39m=\u001b[39m calculer_similarite_cosinus(requete, index_inverse, documents_trouves)\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(resultat, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(res)\n",
      "Cell \u001b[0;32mIn [9], line 5\u001b[0m, in \u001b[0;36mcalculer_similarite_cosinus\u001b[0;34m(requete, index_inverse, documents_trouves)\u001b[0m\n\u001b[1;32m      3\u001b[0m requete \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmoteur vais tester moteur\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m index_requete \u001b[39m=\u001b[39m indexer_requete(requete)\n\u001b[0;32m----> 5\u001b[0m documents_trouves \u001b[39m=\u001b[39m  requeter_documents(requete, index)\n\u001b[1;32m      6\u001b[0m resultat \u001b[39m=\u001b[39m calculer_similarite_cosinus(requete, index_inverse, documents_trouves)\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(resultat, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "Cell \u001b[0;32mIn [7], line 2\u001b[0m, in \u001b[0;36mrequeter_documents\u001b[0;34m(requete, index)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequeter_documents\u001b[39m(requete, index):\n\u001b[0;32m----> 2\u001b[0m     index_requete \u001b[39m=\u001b[39m indexer_requete(requete)\n\u001b[1;32m      3\u001b[0m     documents_trouves \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m mot \u001b[39min\u001b[39;00m index_requete:\n",
      "Cell \u001b[0;32mIn [5], line 3\u001b[0m, in \u001b[0;36mindexer_requete\u001b[0;34m(requete)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mindexer_requete\u001b[39m(requete):\n\u001b[1;32m      2\u001b[0m     index_requete \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m     mots \u001b[39m=\u001b[39m decouper_mots(requete)\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m mot \u001b[39min\u001b[39;00m mots:   \n\u001b[1;32m      5\u001b[0m         \u001b[39mif\u001b[39;00m mot \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m index_requete:\n",
      "Cell \u001b[0;32mIn [3], line 2\u001b[0m, in \u001b[0;36mdecouper_mots\u001b[0;34m(chaine)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecouper_mots\u001b[39m(chaine):\n\u001b[0;32m----> 2\u001b[0m     mots \u001b[39m=\u001b[39m chaine\u001b[39m.\u001b[39;49msplit()\n\u001b[1;32m      3\u001b[0m     \u001b[39mreturn\u001b[39;00m mots\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "#On voit dans la cellule ci-dessus que l'on a copié-collé pas mal de choses\n",
    "#Maintenant nous pouvons créer une fonction qui fait toutes ces opérations \n",
    "\n",
    "def traiter_requete(requete, index, index_inverse):\n",
    "    index_requete = indexer_requete(requete)\n",
    "    documents_trouves =  requeter_documents(requete, index)\n",
    "    resultat = calculer_similarite_cosinus(requete, index_inverse, documents_trouves)\n",
    "    return resultat\n",
    "\n",
    "    \n",
    "for requete in [\"la solidarité\", \"toto titi\", \"droit travail\"]:\n",
    "    resultat = traiter_requete(requete, index, index_inverse)\n",
    "    print(\"Pour la requête %s (%i résultats)\"%(requete, len(resultat)))\n",
    "    for res in sorted(resultat, reverse=True)[:10]:#On se limite aux dix premiers résultats\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### On voit que la présence de \"la\" dans une des requêtes donne des résultats étrange\n",
    "### La suite ce sera de pondérer les termes avec  le tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ponderation_tfidf(index):\n",
    "    import math\n",
    "    #On a besoin de connaître le nombre de documents dans le corpus\n",
    "    all_documents = []\n",
    "    for liste_doc in index.values():\n",
    "        all_documents+=liste_doc\n",
    "    Nb_documents = len(set(all_documents))\n",
    "    \n",
    "    #on reconstruit un index pondéré\n",
    "    index_tf_idf = {}\n",
    "    for mot, liste in index.items():\n",
    "        index_tf_idf[mot] = math.log(Nb_documents/len(liste))\n",
    "        #index_tf_idf[mot]=0\n",
    "    return index_tf_idf\n",
    "\n",
    "def calculer_similarite_cosinus_tf_idf(requete, index_inverse, documents_trouves, index):\n",
    "    from scipy import spatial\n",
    "    \n",
    "    index_requete = indexer_requete(requete)#pour avoir la même structure de dico mot:effectif\n",
    "    resultat = []# où on va stocker les docs et les similarités\n",
    "    index_tf_idf = ponderation_tfidf(index)\n",
    "    for doc in documents_trouves:\n",
    "        #On fait l'union des mots du document en cours et de la requête :\n",
    "        vocabulaire = set(index_requete.keys()).union(index_inverse[doc].keys())\n",
    "        \n",
    "        #On aura un vecteur pour chacun\n",
    "        vecteur, vecteur_requete = [], []\n",
    "        \n",
    "        for mot in vocabulaire:\n",
    "            if mot in index_inverse[doc]:#si le mot est dans le document\n",
    "                #on ajoute son effectif (tf) pondéré par l'idf :\n",
    "                vecteur.append(index_inverse[doc][mot]*index_tf_idf[mot])\n",
    "            else:\n",
    "                vecteur.append(0)# Sile mot est absent de ce document, on ajoute un zéro\n",
    "                \n",
    "            if mot in index_requete:#Idem pour la requête\n",
    "                vecteur_requete.append(index_requete[mot])\n",
    "            else:\n",
    "                vecteur_requete.append(0)#= le mot est absent de la requête\n",
    "        dist=spatial.distance.cosine(vecteur,vecteur_requete )\n",
    "        similarite = 1-dist\n",
    "        resultat.append([similarite, doc])\n",
    "\n",
    "    return resultat # en sortie, des paires [similarité, document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculer_similarite_cosinus_tf_idf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m resultat\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m requete \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mla solidarité\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtoto titi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdroit travail\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m----> 9\u001b[0m     resultat \u001b[39m=\u001b[39m traiter_requete_tf_idf(requete, index, index_inverse)\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPour la requête \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m résultats)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m(requete, \u001b[39mlen\u001b[39m(resultat)))\n\u001b[1;32m     11\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(resultat, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[:\u001b[39m10\u001b[39m]:\u001b[39m#On se limite aux dix premiers résultats\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [11], line 4\u001b[0m, in \u001b[0;36mtraiter_requete_tf_idf\u001b[0;34m(requete, index, index_inverse)\u001b[0m\n\u001b[1;32m      2\u001b[0m index_requete \u001b[39m=\u001b[39m indexer_requete(requete)\n\u001b[1;32m      3\u001b[0m documents_trouves \u001b[39m=\u001b[39m  requeter_documents(requete, index)\n\u001b[0;32m----> 4\u001b[0m resultat \u001b[39m=\u001b[39m calculer_similarite_cosinus_tf_idf(requete, index_inverse, documents_trouves, index)\n\u001b[1;32m      5\u001b[0m \u001b[39mreturn\u001b[39;00m resultat\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculer_similarite_cosinus_tf_idf' is not defined"
     ]
    }
   ],
   "source": [
    "def traiter_requete_tf_idf(requete, index, index_inverse):\n",
    "    index_requete = indexer_requete(requete)\n",
    "    documents_trouves =  requeter_documents(requete, index)\n",
    "    resultat = calculer_similarite_cosinus_tf_idf(requete, index_inverse, documents_trouves, index)\n",
    "    return resultat\n",
    "\n",
    "    \n",
    "for requete in [\"la solidarité\", \"toto titi\", \"droit travail\"]:\n",
    "    resultat = traiter_requete_tf_idf(requete, index, index_inverse)\n",
    "    print(\"Pour la requête %s (%i résultats)\"%(requete, len(resultat)))\n",
    "    for res in sorted(resultat, reverse=True)[:10]:#On se limite aux dix premiers résultats\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
